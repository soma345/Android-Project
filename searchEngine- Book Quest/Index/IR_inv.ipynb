{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import ast\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "import gzip\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "data_dir = '/content/gdrive/My Drive/MachineLearning/'\n",
        "\n",
        "def stopword_handling():\n",
        "  my_file = open(data_dir + 'stopwords.txt', 'r')\n",
        "  stopwords = my_file.readlines()\n",
        "  stopwords = list(map(str.strip, stopwords))\n",
        "\n",
        "def csv_to_dataframe(data_dir):\n",
        "  data = pd.read_csv(data_dir + 'booksummaries.txt', sep = \"\\t\")\n",
        "  data.columns = ['Wikipedia_ID', 'Freebase_ID', 'Title', 'Author', 'Publication_Date', 'Genres', 'Plot']\n",
        "  datatemp = data.copy(deep=True)\n",
        "  data.drop(labels = ['Wikipedia_ID', 'Author', 'Freebase_ID', 'Publication_Date'], inplace = True, axis = 1)\n",
        "  datatemp.drop(labels = ['Wikipedia_ID',  'Freebase_ID', 'Publication_Date'], inplace = True, axis = 1)\n",
        "  return data, datatemp\n",
        "\n",
        "def clean_data(data, datatemp):\n",
        "  data = data.dropna(subset = ['Genres'])\n",
        "  datatemp = datatemp.dropna(subset = ['Genres'])\n",
        "  data.reset_index(drop = True, inplace = True)\n",
        "  datatemp.reset_index(drop = True, inplace = True)\n",
        "  return data, datatemp\n",
        "\n",
        "def genre_to_dict(data, datatemp):\n",
        "  data['Genres'] = data['Genres'].map(lambda x: ast.literal_eval(x))\n",
        "  data['Genres'] = data['Genres'].map(lambda x: list(x.values()))\n",
        "\n",
        "  datatemp['Genres'] = datatemp['Genres'].map(lambda x: ast.literal_eval(x))\n",
        "  print(datatemp)\n",
        "  datatemp['Genres'] = datatemp['Genres'].map(lambda x: list(x.values()))\n",
        "  print(datatemp)\n",
        "  return data, datatemp\n",
        "\n",
        "data, datatemp = csv_to_dataframe(data_dir)\n",
        "data, datatemp = clean_data(data, datatemp)\n",
        "data, datatemp = genre_to_dict(data, datatemp)"
      ],
      "metadata": {
        "id": "UoTcOVhzZs1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7afca7a7-5ba7-4bef-c1fe-2b56bc9ebd52"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "                                Title                Author  \\\n",
            "0                  A Clockwork Orange       Anthony Burgess   \n",
            "1                          The Plague          Albert Camus   \n",
            "2                A Fire Upon the Deep          Vernor Vinge   \n",
            "3      All Quiet on the Western Front  Erich Maria Remarque   \n",
            "4                A Wizard of Earthsea     Ursula K. Le Guin   \n",
            "...                               ...                   ...   \n",
            "12835                  The Third Lynx          Timothy Zahn   \n",
            "12836                  Remote Control            Andy McNab   \n",
            "12837               Transfer of Power           Vince Flynn   \n",
            "12838                         Decoded                 Jay-Z   \n",
            "12839                       Poor Folk    Fyodor Dostoyevsky   \n",
            "\n",
            "                                                  Genres  \\\n",
            "0      {'/m/06n90': 'Science Fiction', '/m/0l67h': 'N...   \n",
            "1      {'/m/02m4t': 'Existentialism', '/m/02xlf': 'Fi...   \n",
            "2      {'/m/03lrw': 'Hard science fiction', '/m/06n90...   \n",
            "3      {'/m/098tmk': 'War novel', '/m/016lj8': 'Roman...   \n",
            "4      {'/m/0dwly': 'Children's literature', '/m/01hm...   \n",
            "...                                                  ...   \n",
            "12835                    {'/m/06n90': 'Science Fiction'}   \n",
            "12836  {'/m/01jfsb': 'Thriller', '/m/02xlf': 'Fiction...   \n",
            "12837   {'/m/01jfsb': 'Thriller', '/m/02xlf': 'Fiction'}   \n",
            "12838                       {'/m/0xdf': 'Autobiography'}   \n",
            "12839  {'/m/02ql9': 'Epistolary novel', '/m/014dfn': ...   \n",
            "\n",
            "                                                    Plot  \n",
            "0       Alex, a teenager living in near-future Englan...  \n",
            "1       The text of The Plague is divided into five p...  \n",
            "2       The novel posits that space around the Milky ...  \n",
            "3       The book tells the story of Paul Bäumer, a Ge...  \n",
            "4       Ged is a young boy on Gont, one of the larger...  \n",
            "...                                                  ...  \n",
            "12835   The story starts with former government agent...  \n",
            "12836   The series follows the character of Nick Ston...  \n",
            "12837   The reader first meets Rapp while he is doing...  \n",
            "12838   The book follows very rough chronological ord...  \n",
            "12839   Makar Devushkin and Varvara Dobroselova are s...  \n",
            "\n",
            "[12840 rows x 4 columns]\n",
            "                                Title                Author  \\\n",
            "0                  A Clockwork Orange       Anthony Burgess   \n",
            "1                          The Plague          Albert Camus   \n",
            "2                A Fire Upon the Deep          Vernor Vinge   \n",
            "3      All Quiet on the Western Front  Erich Maria Remarque   \n",
            "4                A Wizard of Earthsea     Ursula K. Le Guin   \n",
            "...                               ...                   ...   \n",
            "12835                  The Third Lynx          Timothy Zahn   \n",
            "12836                  Remote Control            Andy McNab   \n",
            "12837               Transfer of Power           Vince Flynn   \n",
            "12838                         Decoded                 Jay-Z   \n",
            "12839                       Poor Folk    Fyodor Dostoyevsky   \n",
            "\n",
            "                                                  Genres  \\\n",
            "0      [Science Fiction, Novella, Speculative fiction...   \n",
            "1      [Existentialism, Fiction, Absurdist fiction, N...   \n",
            "2      [Hard science fiction, Science Fiction, Specul...   \n",
            "3                              [War novel, Roman à clef]   \n",
            "4      [Children's literature, Fantasy, Speculative f...   \n",
            "...                                                  ...   \n",
            "12835                                  [Science Fiction]   \n",
            "12836                      [Thriller, Fiction, Suspense]   \n",
            "12837                                [Thriller, Fiction]   \n",
            "12838                                    [Autobiography]   \n",
            "12839            [Epistolary novel, Speculative fiction]   \n",
            "\n",
            "                                                    Plot  \n",
            "0       Alex, a teenager living in near-future Englan...  \n",
            "1       The text of The Plague is divided into five p...  \n",
            "2       The novel posits that space around the Milky ...  \n",
            "3       The book tells the story of Paul Bäumer, a Ge...  \n",
            "4       Ged is a young boy on Gont, one of the larger...  \n",
            "...                                                  ...  \n",
            "12835   The story starts with former government agent...  \n",
            "12836   The series follows the character of Nick Ston...  \n",
            "12837   The reader first meets Rapp while he is doing...  \n",
            "12838   The book follows very rough chronological ord...  \n",
            "12839   Makar Devushkin and Varvara Dobroselova are s...  \n",
            "\n",
            "[12840 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Removing Non-Ascii characters\n",
        "def _removeNonAscii(s): \n",
        "    return \"\".join(i for i in s if ord(i)<128)\n",
        "\n",
        "data['Plot'] = data['Plot'].map(_removeNonAscii)\n",
        "\n",
        "# Tokenizing the words and removing punctuations and stopwords\n",
        "def plot_tokenizer(w):\n",
        "\n",
        "  stop = set(list(string.punctuation) + ['``', \"'s\", \"''\"] + stopwords.words('english'))\n",
        "  return [item for item in word_tokenize(w.lower()) if item not in stop]\n",
        "\n",
        "data['plot_token'] = data['Plot'].map(lambda x: plot_tokenizer(x))"
      ],
      "metadata": {
        "id": "fnH10WKfZ0-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7349938-cc0c-477b-ad83-b93376a9a213"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "def stem(x1):\n",
        "  ps = PorterStemmer()\n",
        "  stemmed = []\n",
        "  for a in x1:\n",
        "    stemmed.append(ps.stem(a))\n",
        "  return stemmed\n",
        "\n",
        "data['plot_token'] = data['plot_token'].apply(lambda x: stem(x)) # this is a dataframe column that has the tokenized and stemmed words"
      ],
      "metadata": {
        "id": "P7IBInOWZ5Kr"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting dataframe column to dictionary\n",
        "docdict = {}\n",
        "for i in range(len(data)):\n",
        "  docdict['doc' + str(i)] = data['plot_token'].iloc[i]"
      ],
      "metadata": {
        "id": "OaGXvuI9Z91d"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqMax, normOfdoc, docNo = [],[],[]\n",
        "dictionary, statOfdoc = {}, [docNo,normOfdoc,freqMax]\n",
        "postingList, indexStruct = [], [dictionary,statOfdoc]\n",
        "posting_idx = 0"
      ],
      "metadata": {
        "id": "LXZhxwDnZ_96"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j = 0\n",
        "for id,doc in docdict.items():\n",
        "  max_freq = 1\n",
        "  docno = id\n",
        "  for word in doc:\n",
        "    if word not in dictionary:\n",
        "        dictionary.update({word:[j,posting_idx]})\n",
        "        postingList.append([j,1])\n",
        "        posting_idx+=1 # keeps track of offset in the posting list\n",
        "    else:\n",
        "      postings = postingList[dictionary[word][1]]\n",
        "      if j == postings[-2]:\n",
        "        postings[-1] += 1\n",
        "        max_freq = max(max_freq,postings[-1])\n",
        "      else:\n",
        "        postings.extend([j,1])\n",
        "  freqMax.append(max_freq)\n",
        "  docNo.append(docno)\n",
        "  j +=1"
      ],
      "metadata": {
        "id": "X6K3i_8daBw2"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_docs = j\n",
        "normOfdoc = [0 for i in range(n_docs)]"
      ],
      "metadata": {
        "id": "xS5BFKg7aDkx"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt,log2\n",
        "def tf(f,norm,K=0.5):\n",
        "\treturn (K + (1-K)*(f/norm))*(1 + log2(f))"
      ],
      "metadata": {
        "id": "8pb-GMCBaIUQ"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def idf(df,N):\n",
        "\treturn log2(N/(1+df)) + 1\t\t"
      ],
      "metadata": {
        "id": "t6EFpfr3aJ7O"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_idf(f,f_norm,df,n_docs,K_f=0.5):\n",
        "\treturn tf(f,f_norm,K_f)*idf(df,n_docs)"
      ],
      "metadata": {
        "id": "PsE9U1sjaLeM"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in dictionary:\n",
        "\t\tval = dictionary[key]\n",
        "\t\tposting = postingList[val[1]]\n",
        "\t\tdfTemp = len(posting) //2\n",
        "\t\tval[0] = dfTemp\n",
        "\t\tidfVal = idf(dfTemp,n_docs)\n",
        "\t\t#prev_doc = 0\n",
        "\t\tfor i in range(dfTemp):\n",
        "\t\t\tdoc_id = posting[2*i]\n",
        "\t\t\tfreq = posting[2*i+1]\n",
        "\t\t\tfreq_max = freqMax[doc_id]\n",
        "\t\t\tf = tf(freq,freq_max)\n",
        "\t\t\tnormOfdoc[doc_id] += (idfVal*f)**2\n",
        "\t\t\t#posting[2*i],prev_doc = posting[2*i]-prev_doc,posting[2*i]\n",
        "\t\t\t#print(posting[2*i],prev_doc)\n"
      ],
      "metadata": {
        "id": "TPDcNUZeaMzm"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normOfdoc = [float(\"{:.3f}\".format(sqrt(val))) for val in normOfdoc]\n",
        "statOfdoc[1] = normOfdoc"
      ],
      "metadata": {
        "id": "66_--hLxaPSw"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with gzip.GzipFile(\"index\"+'.dict', 'w') as f:\n",
        "\tf.write(json.dumps(indexStruct).encode('utf-8')) \n",
        "\n",
        "with gzip.GzipFile(\"postingList\"+'.idx', 'w') as f:\n",
        "\tf.write(json.dumps(postingList).encode('utf-8'))  "
      ],
      "metadata": {
        "id": "F5EAuX4raP4q"
      },
      "execution_count": 201,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of IR_textmethods.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}